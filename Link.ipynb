{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Link Prediction\n",
    "\n",
    "* Given an observed network\n",
    "    * identify missing links\n",
    "    * predict potential links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Heuristic Methods\n",
    "\n",
    "* Common neighbors: number of common neighbors between two nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Jaccard similarity: common neighbors normalized by the size of the joint neighborhood\n",
    "$$ Jaccard(i,j)=\\frac{|\\Gamma(i)\\cap\\Gamma(j)|}{|\\Gamma(i)\\cup\\Gamma(j)|} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Adamic/Adar: number of weighted common neighbors; each neighbors is discounted by its degree.\n",
    "$$ AdamicAdar(i,j)=\\sum_{z\\in\\Gamma(i)\\cap\\Gamma(j)}\\frac{1}{\\log|\\Gamma(z)|} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Distance: length of shortest paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Kats similarity: number of paths between two nodes but the contribution from long paths is discounted.\n",
    "$$ Katz(i,j)=\\sum_{l=1}^{\\infty}\\beta^l~|paths_{i,j}^l|~~~~or~~~~Katz=(I-\\beta A)^{-1}-I$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Rooted Pagerank: the similarty between nodes $i$ and $j$ is the stationary probability of visiting $j$ of a random walk that starts from $i$ and returns to $i$ with probability $1-\\beta$ in every step.\n",
    "$$ Pagerank=(1-\\beta)(I-\\beta D^{-1}A)^{-1} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Collaborative Filtering\n",
    "\n",
    "* A popular method in recommender systems.\n",
    "* Mostly used for bi-partite networks, e.g., users and items, to predict\n",
    "    * which movie a user will watch, what music a user will like, and so on. \n",
    "<img src='Images/collaborativefiltering.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Key idea\n",
    "\n",
    "* Individuals’ preferences can be predicted from similar others’\n",
    "    * If my purchase history is similar to yours, then I will probably buy what you buy next\n",
    "    * If I bought product A and A is often bought together with product B, then I will probably buy B next\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The idea behind collaborative filtering is that individuals’ preferences can be predicted from similar others’ given large-scale population data. For concreteness, let’s consider consumers and products in e-commerce. The idea behind collaborative filtering is the following: we can probably make a good guess on what a consumer will buy next by considering other consumers that have similar purchase histories as this target consumer; on the other hand, for a consumer who has bought product A, I should probably recommend her product B, the product whose buyers have the largest overlap with A’s (e.g., the \"people who bought ... also bought ...\" section seen on most e-commerce platforms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Latent factor model\n",
    "* Each individual is associated with a few latent factors, and so is each product\n",
    "* Interactions between the individuals and the products are determined by the similarity between the individuals and the products in terms of the latent factors.\n",
    "* The latent factors are unknown and to be estimated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "A widely used collaborative filtering technique is the latent factor model. It assumes that each individual is associated with a few latent factors, and so is each product; in other words, the individuals and the products are mapped to a same latent space. And then the (valued) interactions between the individuals and the products - e.g., ratings, likes and dislikes, and purchases - are determined by the distances between the individuals and the products in the latent space. However, the latent factors and the positions are unknown and they are usually estimated by the matrix factorization method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Model\n",
    "\n",
    "* Each user $i$ is associated with a latent vector $P_i=(P_{i1},P_{i2},\\cdots,P_{iK})$  \n",
    "* Each item $j$ is associated with a latent vector $Q_j=(Q_{j1},Q_{j2},\\cdots,Q_{jK})$ \n",
    "* The weighted edge $A_{ij}$ between $i$ and $j$ is assumed to be approximately $P_i\\cdot Q_j$. \n",
    "* In matrix form, $A\\approx P Q^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Estimation\n",
    "\n",
    "* Given the observed $A_{ij}$, the goal is to find the latent vectors that minimize the following cost function:\n",
    "$$\n",
    "\\sum_{(i,j)\\in E} (A_{ij} - \\sum_{k=1}^K P_{ik}Q_{jk})^2  + \\beta(||P||^2 + ||Q||^2),\n",
    "$$\n",
    "    * $E$ is the set of $(i,j)$ pairs whose $A_{ij}$ are known. \n",
    "* This estimation is approximately a factorization of $A$, that is, $A\\approx P Q^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Ratings on Video Games\n",
    "\n",
    "The data is about the world's most popular PC Gaming hub, Steam, which covers over 6,000 video games and a community of millions of users or gamers. The data is organized as a table with 3 columns (variables): user ID, game ID, and rating; and each row (observation) represent the rating from the user on the game.  \n",
    "\n",
    "In total the data has 43,726 observations from 8,203 users and 284 games. The numbers are smaller than the size of the Steam community because we only include games that have been played by at least 50 users and users who have played at least two hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First, load data into R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "dat = read.csv('dataset-steam-2017.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "To obtain a fair evaluation of the method, split the data randomly into a training subset and a test subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "index = sample(seq_len(nrow(dat)), size = floor(0.9*nrow(dat)))\t\n",
    "train = dat[index,]\n",
    "test = dat[-index,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The collaborative filtering method is implemented by the package \"recosystem\", so install it before it can loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "install.packages('recosystem')\n",
    "library('recosystem')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Next, we need to turn the training set into the format required by the recosystem package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "rec_train = data_memory(user_index = train$user_id, \n",
    "                       item_index = train$item_id, \n",
    "                        rating=train$rating,\n",
    "                        index1 = TRUE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "After that we can fit the latent factor model to the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter      tr_rmse          obj\n",
      "   0       0.3715   8.4745e+03\n",
      "   1       0.3141   7.0554e+03\n",
      "   2       0.3004   6.7184e+03\n",
      "   3       0.2939   6.6016e+03\n",
      "   4       0.2894   6.5112e+03\n",
      "   5       0.2862   6.4569e+03\n",
      "   6       0.2839   6.4081e+03\n",
      "   7       0.2823   6.4071e+03\n",
      "   8       0.2805   6.3493e+03\n",
      "   9       0.2795   6.3336e+03\n",
      "  10       0.2787   6.3294e+03\n",
      "  11       0.2779   6.3163e+03\n",
      "  12       0.2770   6.2895e+03\n",
      "  13       0.2765   6.2778e+03\n",
      "  14       0.2762   6.2915e+03\n",
      "  15       0.2754   6.2547e+03\n",
      "  16       0.2754   6.2721e+03\n",
      "  17       0.2747   6.2554e+03\n",
      "  18       0.2746   6.2585e+03\n",
      "  19       0.2744   6.2647e+03\n"
     ]
    }
   ],
   "source": [
    "rec = Reco()\n",
    "res = rec$train(rec_train, opts = list(ndim=10, verbose=TRUE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "where \"ndim\"\" in the second line specifies the number of latent factors, which is set to 10 in this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally, we assess the predictive performance of the method on the test set. But first we still need to convert the test set to the format required by the package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "rec_test = data_memory(user_index = test$user_id, \n",
    "                      item_index = test$item_id,\n",
    "                      index1 = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then, the mean squared error of the predictions of ratings can be calculated as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0946955338813839"
      ],
      "text/latex": [
       "0.0946955338813839"
      ],
      "text/markdown": [
       "0.0946955338813839"
      ],
      "text/plain": [
       "[1] 0.09469553"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = rec$predict(rec_test, out_pred = out_memory())\n",
    "sum((test$rating-pred)^2) / length(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exponential Random Graph Model (ERGM)\n",
    "\n",
    "* A probability model for networks\n",
    "* Similar to logistic regression in predicting edges\n",
    "* Can handle attributes of nodes and edges\n",
    "* Can handle network structures such as transitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The expoential random graph model is for general link predictions, especially when nodes have attributes. It is a parametric model for the probability distribution of networks. It can be viewed as a generalization of the Logistic regression to predict edges: for every pair of nodes, the outcome is whether or not there is an edge between the two nodes and predictors are any attributes of the nodes. However, ERGM is more general and models the probability of the network as a whole instead of modelling every pair of nodes. Consequently, it even allows using any statistics of a network including global properties such as edge density and global transitivity. Most importantly, by modelling the probability of a whole network ERGM considers the correlation structure between pairs, which is overlooked in the Logistic regression model where the pairs are assumed to be independent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Logistic regression model\n",
    "\n",
    "* Outcome variable $A_{ij}$\n",
    "* Predictors: attributes of nodes $i$ and $j$, $x(i)$, $x(j)$, and $x(i,j)$\n",
    "* Logistic regression\n",
    "$$\n",
    "A_{ij} \\sim c_0 + c_1 x(i) + c_2 x(j) + c_3 x(i,j)\n",
    "$$\n",
    "* Assumption: the pairs are independent from each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Exponential Random Graph Model\n",
    "\n",
    "* Let $A$ be a random adjacency matrix and $a$ be a realization of $A$. \n",
    "* Let $x(a)=(x_1,…,x_p)$ to be the vector of statistics of the network $a$ that we are interested in, e.g.,   $x(a)=$(number of triangles, number of edges between people of same race, number of edges between people of similar grades).\n",
    "* ERGM specifies a probability model on $A$ as the following:\n",
    "$$\n",
    "P(A=a)=\\frac{\\exp(c \\cdot x(a))}{k(c)},\n",
    "$$\n",
    "    * where $c$ is a vector of coefficients corresponding the statistics $x(a)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Estimation\n",
    "\n",
    "* Given an observed network and its adjacency matrix $a$, our goal is to find the coefficients $c$ that maximize the probability of observing $a$ based on the model. \n",
    "* But we only have one observation of the network, how to estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "However, most of the time we only observe one or two snapshots of the network under study; how can we estimate this model with only one data point? This issue is addressed by advanced MCMC techniques, but the estimation process is quite complicated and is hence beyond the scope of this course. The rough idea behind it is similar to the maximal likelihood estimation for logistic regressions. Finally, the estimates of the coefficients and their statistical significance tell us how much each statistic in the vector $x(a)$ contributes to the formation of edges and the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* The ERGM model can be written as\n",
    "$$\n",
    "logit(A_{ij}=1|a_{ij}^c) = c \\cdot(x(a_{ij}^+) - x(a_{ij}^- )).\n",
    "$$\n",
    "    * $a_{ij}^c$ means all the pairs of nodes except for the $(i,j)$ pair\n",
    "    * $a_{ij}^+$ and $a_{ij}^-$ are the same as $a$ but with the entry $a_{ij}$ set to 1 and 0, respectively\n",
    "* Estimation is done by advanced MCMC techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Model\n",
    "$$\n",
    "P(A=a)=\\frac{\\exp(c \\cdot x(a))}{k(c)},\n",
    "$$\n",
    "* The coefficients and their statistical significance tell us how much each statistic in the vector $x(a)$ contributes to the formation of edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: UK Faculty Network\n",
    "\n",
    "The data is about a social network consisting of 81 nodes with each representing a faculty member of a UK university, and the edges of the network represent friendships between the faculty members. There are 817 undirected, unweighted edges in total. Here we are interested in predicting edges based on the department affiliations of the faculty members."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First, load the network data into R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = read.csv('dataset-ukfaculty-2008-nodes.csv') \n",
    "edges = read.csv('dataset-ukfaculty-2008-edges.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The ERGM is included in the \"statnet\" package. We need to load the  package in order to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: tergm\n",
      "Loading required package: statnet.common\n",
      "\n",
      "Attaching package: ‘statnet.common’\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    order\n",
      "\n",
      "Loading required package: ergm\n",
      "Loading required package: network\n",
      "network: Classes for Relational Data\n",
      "Version 1.13.0.1 created on 2015-08-31.\n",
      "copyright (c) 2005, Carter T. Butts, University of California-Irvine\n",
      "                    Mark S. Handcock, University of California -- Los Angeles\n",
      "                    David R. Hunter, Penn State University\n",
      "                    Martina Morris, University of Washington\n",
      "                    Skye Bender-deMoll, University of Washington\n",
      " For citation information, type citation(\"network\").\n",
      " Type help(\"network-package\") to get started.\n",
      "\n",
      "\n",
      "ergm: version 3.9.4, created on 2018-08-15\n",
      "Copyright (c) 2018, Mark S. Handcock, University of California -- Los Angeles\n",
      "                    David R. Hunter, Penn State University\n",
      "                    Carter T. Butts, University of California -- Irvine\n",
      "                    Steven M. Goodreau, University of Washington\n",
      "                    Pavel N. Krivitsky, University of Wollongong\n",
      "                    Martina Morris, University of Washington\n",
      "                    with contributions from\n",
      "                    Li Wang\n",
      "                    Kirk Li, University of Washington\n",
      "                    Skye Bender-deMoll, University of Washington\n",
      "Based on \"statnet\" project software (statnet.org).\n",
      "For license and citation information see statnet.org/attribution\n",
      "or type citation(\"ergm\").\n",
      "\n",
      "NOTE: Versions before 3.6.1 had a bug in the implementation of the bd()\n",
      "constriant which distorted the sampled distribution somewhat. In\n",
      "addition, Sampson's Monks datasets had mislabeled vertices. See the\n",
      "NEWS and the documentation for more details.\n",
      "\n",
      "\n",
      "Attaching package: ‘ergm’\n",
      "\n",
      "The following objects are masked from ‘package:statnet.common’:\n",
      "\n",
      "    colMeans.mcmc.list, sweep.mcmc.list\n",
      "\n",
      "Loading required package: networkDynamic\n",
      "\n",
      "networkDynamic: version 0.9.0, created on 2016-01-12\n",
      "Copyright (c) 2016, Carter T. Butts, University of California -- Irvine\n",
      "                    Ayn Leslie-Cook, University of Washington\n",
      "                    Pavel N. Krivitsky, University of Wollongong\n",
      "                    Skye Bender-deMoll, University of Washington\n",
      "                    with contributions from\n",
      "                    Zack Almquist, University of California -- Irvine\n",
      "                    David R. Hunter, Penn State University\n",
      "                    Li Wang\n",
      "                    Kirk Li, University of Washington\n",
      "                    Steven M. Goodreau, University of Washington\n",
      "                    Jeffrey Horner\n",
      "                    Martina Morris, University of Washington\n",
      "Based on \"statnet\" project software (statnet.org).\n",
      "For license and citation information see statnet.org/attribution\n",
      "or type citation(\"networkDynamic\").\n",
      "\n",
      "Warning message:\n",
      "“replacing previous import ‘statnet.common::sweep.mcmc.list’ by ‘ergm::sweep.mcmc.list’ when loading ‘tergm’”Warning message:\n",
      "“replacing previous import ‘statnet.common::colMeans.mcmc.list’ by ‘ergm::colMeans.mcmc.list’ when loading ‘tergm’”Warning message:\n",
      "“'ergm.MHP.table' is deprecated.\n",
      "See help(\"Deprecated\")”Warning message:\n",
      "“Function ergm.ConstraintImplications() has been deprecated in favor of specifying the implications in the InitErgmConstraint.*() functions, and has no effect.”\n",
      "tergm: version 3.4.1, created on 2017-09-12\n",
      "Copyright (c) 2017, Pavel N. Krivitsky, University of Wollongong\n",
      "                    Mark S. Handcock, University of California -- Los Angeles\n",
      "                    with contributions from\n",
      "                    David R. Hunter, Penn State University\n",
      "                    Steven M. Goodreau, University of Washington\n",
      "                    Martina Morris, University of Washington\n",
      "                    Nicole Bohme Carnegie, New York University\n",
      "                    Carter T. Butts, University of California -- Irvine\n",
      "                    Ayn Leslie-Cook, University of Washington\n",
      "                    Skye Bender-deMoll\n",
      "                    Li Wang\n",
      "                    Kirk Li, University of Washington\n",
      "Based on \"statnet\" project software (statnet.org).\n",
      "For license and citation information see statnet.org/attribution\n",
      "or type citation(\"tergm\").\n",
      "\n",
      "Loading required package: ergm.count\n",
      "Warning message:\n",
      "“replacing previous import ‘statnet.common::sweep.mcmc.list’ by ‘ergm::sweep.mcmc.list’ when loading ‘ergm.count’”Warning message:\n",
      "“replacing previous import ‘statnet.common::colMeans.mcmc.list’ by ‘ergm::colMeans.mcmc.list’ when loading ‘ergm.count’”Warning message:\n",
      "“Function ergm.init.methods() has been deprecated in favor of specifying init_methods in InitErgmReference.*() functions, and has no effect.”\n",
      "ergm.count: version 3.2.2, created on 2016-03-29\n",
      "Copyright (c) 2016, Pavel N. Krivitsky, University of Wollongong\n",
      "                    with contributions from\n",
      "                    Mark S. Handcock, University of California -- Los Angeles\n",
      "                    David R. Hunter, Penn State University\n",
      "Based on \"statnet\" project software (statnet.org).\n",
      "For license and citation information see statnet.org/attribution\n",
      "or type citation(\"ergm.count\").\n",
      "\n",
      "NOTE: The form of the term ‘CMP’ has been changed in version 3.2 of\n",
      "‘ergm.count’. See the news or help('CMP') for more information.\n",
      "\n",
      "Loading required package: sna\n",
      "sna: Tools for Social Network Analysis\n",
      "Version 2.4 created on 2016-07-23.\n",
      "copyright (c) 2005, Carter T. Butts, University of California-Irvine\n",
      " For citation information, type citation(\"sna\").\n",
      " Type help(package=\"sna\") to get started.\n",
      "\n",
      "Warning message:\n",
      "“replacing previous import ‘statnet.common::sweep.mcmc.list’ by ‘ergm::sweep.mcmc.list’ when loading ‘statnet’”Warning message:\n",
      "“replacing previous import ‘statnet.common::colMeans.mcmc.list’ by ‘ergm::colMeans.mcmc.list’ when loading ‘statnet’”\n",
      "statnet: version 2016.9, created on 2016-08-29\n",
      "Copyright (c) 2016, Mark S. Handcock, University of California -- Los Angeles\n",
      "                    David R. Hunter, Penn State University\n",
      "                    Carter T. Butts, University of California -- Irvine\n",
      "                    Steven M. Goodreau, University of Washington\n",
      "                    Pavel N. Krivitsky, University of Wollongong\n",
      "                    Skye Bender-deMoll\n",
      "                    Martina Morris, University of Washington\n",
      "Based on \"statnet\" project software (statnet.org).\n",
      "For license and citation information see statnet.org/attribution\n",
      "or type citation(\"statnet\").\n",
      "\n",
      "\n",
      "There are updates for the following statnet packages on CRAN:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Installed  ReposVer Built  \n",
      "ergm           \"3.9.4\"    \"3.10.4\" \"3.4.4\"\n",
      "ergm.count     \"3.2.2\"    \"3.4.0\"  \"3.4.0\"\n",
      "network        \"1.13.0.1\" \"1.15\"   \"3.4.4\"\n",
      "networkDynamic \"0.9.0\"    \"0.10.0\" \"3.4.0\"\n",
      "tergm          \"3.4.1\"    \"3.6.1\"  \"3.4.1\"\n",
      "tsna           \"0.2.0\"    \"0.3.0\"  \"3.4.0\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restart R and use \"statnet::update_statnet()\" to get the updates.\n"
     ]
    }
   ],
   "source": [
    "install.packages('statnet')\n",
    "library('statnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Next, we can turn the node and edge tables into a network object by the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "colnames(edges)=c('head','tail')\n",
    "G = network(edges, directed = F, matrix.type='edgelist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Then we need to set the attributes of the nodes, which can done as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "G %v% 'dept' = nodes$dept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Finally, we fit the ERGM to the network with two network statistics\n",
    "    * The number of edges  \n",
    "    * The number of edges between nodes from the same department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting maximum pseudolikelihood estimation (MPLE):\n",
      "Evaluating the predictor and response matrix.\n",
      "Maximizing the pseudolikelihood.\n",
      "Finished MPLE.\n",
      "Stopping at the initial estimate.\n",
      "Evaluating log-likelihood at the estimate. \n"
     ]
    }
   ],
   "source": [
    "model = ergm(G ~ edges + nodematch('dept'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The estimation results can be checked as with a regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "==========================\n",
       "Summary of model fit\n",
       "==========================\n",
       "\n",
       "Formula:   G ~ edges + nodematch(\"dept\")\n",
       "\n",
       "Iterations:  6 out of 20 \n",
       "\n",
       "Monte Carlo MLE Results:\n",
       "               Estimate Std. Error MCMC % z value Pr(>|z|)    \n",
       "edges          -2.83855    0.09353      0  -30.35   <1e-04 ***\n",
       "nodematch.dept  2.57248    0.11235      0   22.90   <1e-04 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "     Null Deviance: 4492  on 3240  degrees of freedom\n",
       " Residual Deviance: 2374  on 3238  degrees of freedom\n",
       " \n",
       "AIC: 2378    BIC: 2391    (Smaller is better.) "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Excercise: How to predict?\n",
    "\n",
    "* Use simulate to simulate networks\n",
    "* Use the simulated network to measure the probability of each potential edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "Ahat=matrix(0, 81, 81)\n",
    "\n",
    "for (i in 1:10) {\n",
    "  a = simulate(model)\n",
    "  Ahat = Ahat + as.matrix(a)\n",
    "}\n",
    "\n",
    "Ahat=Ahat/10"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.4"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": false,
   "toc_threshold": 4,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
